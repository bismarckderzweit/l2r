{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "homepath =  'MQ2008/Fold1/'\n",
    "train_path = homepath + 'train.txt'\n",
    "test_path =  homepath + 'test.txt'\n",
    "model_dest = 'model/Lambdarank_model.txt'\n",
    "k = 1 # k: shap k, we select the top kexample to do analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_iterations` in params. Will use it instead of argument\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's ndcg@10: 0.795294\n",
      "[2]\ttraining's ndcg@10: 0.825484\n",
      "[3]\ttraining's ndcg@10: 0.840332\n",
      "[4]\ttraining's ndcg@10: 0.846315\n",
      "[5]\ttraining's ndcg@10: 0.851988\n",
      "[6]\ttraining's ndcg@10: 0.854417\n",
      "[7]\ttraining's ndcg@10: 0.854734\n",
      "[8]\ttraining's ndcg@10: 0.857192\n",
      "[9]\ttraining's ndcg@10: 0.857863\n",
      "[10]\ttraining's ndcg@10: 0.861034\n",
      "[11]\ttraining's ndcg@10: 0.862943\n",
      "[12]\ttraining's ndcg@10: 0.864337\n",
      "[13]\ttraining's ndcg@10: 0.865535\n",
      "[14]\ttraining's ndcg@10: 0.865346\n",
      "[15]\ttraining's ndcg@10: 0.868912\n",
      "[16]\ttraining's ndcg@10: 0.868667\n",
      "[17]\ttraining's ndcg@10: 0.871131\n",
      "[18]\ttraining's ndcg@10: 0.873049\n",
      "[19]\ttraining's ndcg@10: 0.873006\n",
      "[20]\ttraining's ndcg@10: 0.87409\n",
      "[21]\ttraining's ndcg@10: 0.875678\n",
      "[22]\ttraining's ndcg@10: 0.879084\n",
      "[23]\ttraining's ndcg@10: 0.87978\n",
      "[24]\ttraining's ndcg@10: 0.879835\n",
      "[25]\ttraining's ndcg@10: 0.881396\n",
      "[26]\ttraining's ndcg@10: 0.882057\n",
      "[27]\ttraining's ndcg@10: 0.88215\n",
      "[28]\ttraining's ndcg@10: 0.881965\n",
      "[29]\ttraining's ndcg@10: 0.882816\n",
      "[30]\ttraining's ndcg@10: 0.88281\n",
      "[31]\ttraining's ndcg@10: 0.883115\n",
      "[32]\ttraining's ndcg@10: 0.883733\n",
      "[33]\ttraining's ndcg@10: 0.883839\n",
      "[34]\ttraining's ndcg@10: 0.884803\n",
      "[35]\ttraining's ndcg@10: 0.884902\n",
      "[36]\ttraining's ndcg@10: 0.885395\n",
      "[37]\ttraining's ndcg@10: 0.885896\n",
      "[38]\ttraining's ndcg@10: 0.886134\n",
      "[39]\ttraining's ndcg@10: 0.888249\n",
      "[40]\ttraining's ndcg@10: 0.888212\n",
      "[41]\ttraining's ndcg@10: 0.888869\n",
      "[42]\ttraining's ndcg@10: 0.889326\n",
      "[43]\ttraining's ndcg@10: 0.890033\n",
      "[44]\ttraining's ndcg@10: 0.890507\n",
      "[45]\ttraining's ndcg@10: 0.890928\n",
      "[46]\ttraining's ndcg@10: 0.891107\n",
      "[47]\ttraining's ndcg@10: 0.891325\n",
      "[48]\ttraining's ndcg@10: 0.891844\n",
      "[49]\ttraining's ndcg@10: 0.892517\n",
      "[50]\ttraining's ndcg@10: 0.89303\n",
      "[51]\ttraining's ndcg@10: 0.893689\n",
      "[52]\ttraining's ndcg@10: 0.896163\n",
      "[53]\ttraining's ndcg@10: 0.896262\n",
      "[54]\ttraining's ndcg@10: 0.897053\n",
      "[55]\ttraining's ndcg@10: 0.898355\n",
      "[56]\ttraining's ndcg@10: 0.898308\n",
      "[57]\ttraining's ndcg@10: 0.898735\n",
      "[58]\ttraining's ndcg@10: 0.899027\n",
      "[59]\ttraining's ndcg@10: 0.899367\n",
      "[60]\ttraining's ndcg@10: 0.899376\n",
      "[61]\ttraining's ndcg@10: 0.899165\n",
      "[62]\ttraining's ndcg@10: 0.89977\n",
      "[63]\ttraining's ndcg@10: 0.901389\n",
      "[64]\ttraining's ndcg@10: 0.901847\n",
      "[65]\ttraining's ndcg@10: 0.902444\n",
      "[66]\ttraining's ndcg@10: 0.90306\n",
      "[67]\ttraining's ndcg@10: 0.903529\n",
      "[68]\ttraining's ndcg@10: 0.903769\n",
      "[69]\ttraining's ndcg@10: 0.903556\n",
      "[70]\ttraining's ndcg@10: 0.904386\n",
      "[71]\ttraining's ndcg@10: 0.904435\n",
      "[72]\ttraining's ndcg@10: 0.904827\n",
      "[73]\ttraining's ndcg@10: 0.905203\n",
      "[74]\ttraining's ndcg@10: 0.905613\n",
      "[75]\ttraining's ndcg@10: 0.905802\n",
      "[76]\ttraining's ndcg@10: 0.905486\n",
      "[77]\ttraining's ndcg@10: 0.905814\n",
      "[78]\ttraining's ndcg@10: 0.905528\n",
      "[79]\ttraining's ndcg@10: 0.906676\n",
      "[80]\ttraining's ndcg@10: 0.906614\n",
      "[81]\ttraining's ndcg@10: 0.907299\n",
      "[82]\ttraining's ndcg@10: 0.907422\n",
      "[83]\ttraining's ndcg@10: 0.90898\n",
      "[84]\ttraining's ndcg@10: 0.909918\n",
      "[85]\ttraining's ndcg@10: 0.910115\n",
      "[86]\ttraining's ndcg@10: 0.910387\n",
      "[87]\ttraining's ndcg@10: 0.910001\n",
      "[88]\ttraining's ndcg@10: 0.910164\n",
      "[89]\ttraining's ndcg@10: 0.910079\n",
      "[90]\ttraining's ndcg@10: 0.910505\n",
      "[91]\ttraining's ndcg@10: 0.910256\n",
      "[92]\ttraining's ndcg@10: 0.911493\n",
      "[93]\ttraining's ndcg@10: 0.911614\n",
      "[94]\ttraining's ndcg@10: 0.911615\n",
      "[95]\ttraining's ndcg@10: 0.911562\n",
      "[96]\ttraining's ndcg@10: 0.911505\n",
      "[97]\ttraining's ndcg@10: 0.911562\n",
      "[98]\ttraining's ndcg@10: 0.911813\n",
      "[99]\ttraining's ndcg@10: 0.911907\n",
      "[100]\ttraining's ndcg@10: 0.911882\n",
      "[101]\ttraining's ndcg@10: 0.912224\n",
      "[102]\ttraining's ndcg@10: 0.912371\n",
      "[103]\ttraining's ndcg@10: 0.912367\n",
      "[104]\ttraining's ndcg@10: 0.912408\n",
      "[105]\ttraining's ndcg@10: 0.912464\n",
      "[106]\ttraining's ndcg@10: 0.913377\n",
      "[107]\ttraining's ndcg@10: 0.913597\n",
      "[108]\ttraining's ndcg@10: 0.913606\n",
      "[109]\ttraining's ndcg@10: 0.914161\n",
      "[110]\ttraining's ndcg@10: 0.914364\n",
      "[111]\ttraining's ndcg@10: 0.914828\n",
      "[112]\ttraining's ndcg@10: 0.914888\n",
      "[113]\ttraining's ndcg@10: 0.914726\n",
      "[114]\ttraining's ndcg@10: 0.914908\n",
      "[115]\ttraining's ndcg@10: 0.915248\n",
      "[116]\ttraining's ndcg@10: 0.915228\n",
      "[117]\ttraining's ndcg@10: 0.915368\n",
      "[118]\ttraining's ndcg@10: 0.915569\n",
      "[119]\ttraining's ndcg@10: 0.915536\n",
      "[120]\ttraining's ndcg@10: 0.915455\n",
      "[121]\ttraining's ndcg@10: 0.915948\n",
      "[122]\ttraining's ndcg@10: 0.916215\n",
      "[123]\ttraining's ndcg@10: 0.916367\n",
      "[124]\ttraining's ndcg@10: 0.916183\n",
      "[125]\ttraining's ndcg@10: 0.916274\n",
      "[126]\ttraining's ndcg@10: 0.916198\n",
      "[127]\ttraining's ndcg@10: 0.915692\n",
      "[128]\ttraining's ndcg@10: 0.916462\n",
      "[129]\ttraining's ndcg@10: 0.916839\n",
      "[130]\ttraining's ndcg@10: 0.916932\n",
      "[131]\ttraining's ndcg@10: 0.916984\n",
      "[132]\ttraining's ndcg@10: 0.917192\n",
      "[133]\ttraining's ndcg@10: 0.917172\n",
      "[134]\ttraining's ndcg@10: 0.917574\n",
      "[135]\ttraining's ndcg@10: 0.917723\n",
      "[136]\ttraining's ndcg@10: 0.91798\n",
      "[137]\ttraining's ndcg@10: 0.918121\n",
      "[138]\ttraining's ndcg@10: 0.918263\n",
      "[139]\ttraining's ndcg@10: 0.91835\n",
      "[140]\ttraining's ndcg@10: 0.918517\n",
      "[141]\ttraining's ndcg@10: 0.918604\n",
      "[142]\ttraining's ndcg@10: 0.918738\n",
      "[143]\ttraining's ndcg@10: 0.919257\n",
      "[144]\ttraining's ndcg@10: 0.919317\n",
      "[145]\ttraining's ndcg@10: 0.920085\n",
      "[146]\ttraining's ndcg@10: 0.920138\n",
      "[147]\ttraining's ndcg@10: 0.920507\n",
      "[148]\ttraining's ndcg@10: 0.921142\n",
      "[149]\ttraining's ndcg@10: 0.921211\n",
      "[150]\ttraining's ndcg@10: 0.921225\n",
      "[151]\ttraining's ndcg@10: 0.922346\n",
      "[152]\ttraining's ndcg@10: 0.923316\n",
      "[153]\ttraining's ndcg@10: 0.923382\n",
      "[154]\ttraining's ndcg@10: 0.923499\n",
      "[155]\ttraining's ndcg@10: 0.923423\n",
      "[156]\ttraining's ndcg@10: 0.923884\n",
      "[157]\ttraining's ndcg@10: 0.923939\n",
      "[158]\ttraining's ndcg@10: 0.923912\n",
      "[159]\ttraining's ndcg@10: 0.924346\n",
      "[160]\ttraining's ndcg@10: 0.924471\n",
      "[161]\ttraining's ndcg@10: 0.924522\n",
      "[162]\ttraining's ndcg@10: 0.924262\n",
      "[163]\ttraining's ndcg@10: 0.92459\n",
      "[164]\ttraining's ndcg@10: 0.924892\n",
      "[165]\ttraining's ndcg@10: 0.92483\n",
      "[166]\ttraining's ndcg@10: 0.924945\n",
      "[167]\ttraining's ndcg@10: 0.925095\n",
      "[168]\ttraining's ndcg@10: 0.925823\n",
      "[169]\ttraining's ndcg@10: 0.925254\n",
      "[170]\ttraining's ndcg@10: 0.926005\n",
      "[171]\ttraining's ndcg@10: 0.926185\n",
      "[172]\ttraining's ndcg@10: 0.926204\n",
      "[173]\ttraining's ndcg@10: 0.926856\n",
      "[174]\ttraining's ndcg@10: 0.926954\n",
      "[175]\ttraining's ndcg@10: 0.927155\n",
      "[176]\ttraining's ndcg@10: 0.92744\n",
      "[177]\ttraining's ndcg@10: 0.927663\n",
      "[178]\ttraining's ndcg@10: 0.927773\n",
      "[179]\ttraining's ndcg@10: 0.927935\n",
      "[180]\ttraining's ndcg@10: 0.928271\n",
      "[181]\ttraining's ndcg@10: 0.928332\n",
      "[182]\ttraining's ndcg@10: 0.928469\n",
      "[183]\ttraining's ndcg@10: 0.929035\n",
      "[184]\ttraining's ndcg@10: 0.929179\n",
      "[185]\ttraining's ndcg@10: 0.929268\n",
      "[186]\ttraining's ndcg@10: 0.929206\n",
      "[187]\ttraining's ndcg@10: 0.929303\n",
      "[188]\ttraining's ndcg@10: 0.92982\n",
      "[189]\ttraining's ndcg@10: 0.929845\n",
      "[190]\ttraining's ndcg@10: 0.929988\n",
      "[191]\ttraining's ndcg@10: 0.930045\n",
      "[192]\ttraining's ndcg@10: 0.930353\n",
      "[193]\ttraining's ndcg@10: 0.930643\n",
      "[194]\ttraining's ndcg@10: 0.930742\n",
      "[195]\ttraining's ndcg@10: 0.930562\n",
      "[196]\ttraining's ndcg@10: 0.930854\n",
      "[197]\ttraining's ndcg@10: 0.930859\n",
      "[198]\ttraining's ndcg@10: 0.930846\n",
      "[199]\ttraining's ndcg@10: 0.930853\n",
      "[200]\ttraining's ndcg@10: 0.931069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting feature_perturbation = \"tree_path_dependent\" because no background data was given.\n",
      "The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "The sklearn.ensemble.iforest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "The sklearn.ensemble.gradient_boosting module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C extension was not built during install!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import shap\n",
    "from sklearn import datasets as ds\n",
    "import lightgbm as lgb\n",
    "\n",
    "def load_data(feats, group):\n",
    "    x_train, y_train = ds.load_svmlight_file(feats)\n",
    "    q_train = np.loadtxt(group)\n",
    "    return x_train, y_train, q_train\n",
    "\n",
    "import lightgbm as lgb\n",
    "def train(x_train, y_train, q_train, model_save_path):\n",
    "    '''\n",
    "    模型的训练和保存\n",
    "    '''\n",
    "    train_data = lgb.Dataset(x_train, label=y_train, group=q_train)\n",
    "    params = {\n",
    "        'task': 'train',  # 执行的任务类型\n",
    "        'boosting_type': 'gbrt',  # 基学习器\n",
    "        'objective': 'lambdarank',  # 排序任务(目标函数)\n",
    "        'metric': 'ndcg',  # 度量的指标(评估函数)\n",
    "        'max_position': 10,  # @NDCG 位置优化\n",
    "        'metric_freq': 1,  # 每隔多少次输出一次度量结果\n",
    "        'train_metric': True,  # 训练时就输出度量结果\n",
    "        'ndcg_at': [10],\n",
    "        'max_bin': 255,  # 一个整数，表示最大的桶的数量。默认值为 255。lightgbm 会根据它来自动压缩内存。如max_bin=255 时，则lightgbm 将使用uint8 来表示特征的每一个值。\n",
    "        'num_iterations': 200,  # 迭代次数，即生成的树的棵数\n",
    "        'learning_rate': 0.01,  # 学习率\n",
    "        'num_leaves': 31,  # 叶子数\n",
    "        # 'max_depth':6,\n",
    "        'tree_learner': 'serial',  # 用于并行学习，‘serial’： 单台机器的tree learner\n",
    "        'min_data_in_leaf': 30,  # 一个叶子节点上包含的最少样本数量\n",
    "        'verbose': 2  # 显示训练时的信息\n",
    "    }\n",
    "    gbm = lgb.train(params, train_data, valid_sets=[train_data])\n",
    "    gbm.save_model(model_save_path)\n",
    "    return gbm\n",
    "\n",
    "data_feats ='feats.txt'\n",
    "data_group = 'group.txt'\n",
    "model_path = 'model.mod'\n",
    "x_train, y_train, q_train = load_data(data_feats, data_group)\n",
    "gbm = train(x_train, y_train, q_train, model_path)\n",
    "explainer = shap.TreeExplainer(gbm)\n",
    "# shap_values  = explainer.shap_values(x_train)\n",
    "# shap.summary_plot(shap_values, x_train )\n",
    "\n",
    "# shap_values = np.array(shap_values)\n",
    "# x_train = np.array(shap_values)\n",
    "# shap.dependence_plot(\"Feature 10\", shap_values, x_train)\n",
    "# shap.summary_plot(shap_values, x_train, plot_type=\"bar\")\n",
    "# shap.force_plot(explainer.expected_value, shap_values[0,:], x_train[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.95466746e-02,  1.90149805e-03,  1.00364323e-02,\n",
       "         3.59747511e-04, -1.76265937e-03,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.05531021e-02, -2.58484246e-03,\n",
       "         7.91989969e-03, -2.26728269e-04, -1.51882868e-02,\n",
       "        -4.70992284e-02,  6.44824105e-02,  5.89243984e-03,\n",
       "        -2.31457124e-03,  2.67009773e-02,  3.51366384e-02,\n",
       "        -8.62951893e-03,  6.01892679e-02,  1.37682372e-01,\n",
       "        -8.33245319e-03, -1.76988428e-04,  5.03773416e-04,\n",
       "        -8.51288485e-04,  2.29836084e-01,  1.07226026e-01,\n",
       "        -6.08008246e-03,  1.56385710e-02,  1.54927323e-04,\n",
       "         1.40426130e-03,  8.98980045e-04,  2.23685740e-03,\n",
       "         4.39630557e-02,  2.45602962e-02,  3.29502196e-01,\n",
       "         8.77603107e-02,  8.45416948e-03,  4.24004851e-02,\n",
       "         0.00000000e+00, -4.24619984e-02, -4.65935506e-03,\n",
       "         3.84846735e-02]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values  = explainer.shap_values(x_train[0])\n",
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractYquery(split):\n",
    "    y_query = ''\n",
    "    y_query +=(split[0] + ' ' +split[1] +' ')\n",
    "    return y_query\n",
    "\n",
    "def extractQuery(split):\n",
    "    Query = ''\n",
    "    for i in range(48,57):\n",
    "        Query += (split[i] + ' ')\n",
    "    return Query    \n",
    "    \n",
    "def extractFeatures(split):\n",
    "    features = []\n",
    "    for i in range(2,48):\n",
    "        features.append(float(split[i].split(':')[1]))\n",
    "    return features\n",
    "\n",
    "def get_microsoft_data(file_path):\n",
    "    with open(file_path, 'r') as fp:\n",
    "        X_train = []\n",
    "        y_query= []\n",
    "        Query = []\n",
    "        for data in fp:\n",
    "            split = data.split()\n",
    "            y_query.append(extractYquery(split))\n",
    "            Query.append(extractQuery(split))\n",
    "            X_train.append(extractFeatures(split))\n",
    "    return X_train, y_query, Query\n",
    "\n",
    "X_train, y_query_train, Query_train= get_microsoft_data(train_path)\n",
    "X_train = np.array(X_train)\n",
    "X_test, y_query_test, Query_test= get_microsoft_data(test_path)\n",
    "X_test = np.array(X_test) \n",
    "\n",
    "# rewrite a txt file for subprocessing\n",
    "def rewrite(X, y_query, Query, restore_path):\n",
    "    with open(restore_path,'w') as f:\n",
    "        for i in range(len(X)):\n",
    "            line = \"\"\n",
    "            line += y_query[(i%len(y_query))].split(':')[0] + ':'+ str(i) +' ' \n",
    "            for j in range(len(X[i])):\n",
    "                line += ((str(j+1))+\":\"+str(X[i][j])+\" \")\n",
    "            line += Query[(i%len(Query))] + \"\\n\"\n",
    "            f.write(line)  \n",
    "            \n",
    "def evaluate():\n",
    "    args = ['java', '-jar', 'RankLib-2.12.jar', '-load', 'model/MART_model.txt', '-test', 'temp_data/restore_shapk_{}.txt'.format(tmp_test_y_query[0].split(':')[-1].split()[0]),\n",
    "            '-metric2T', 'NDCG@10', '-gmax', '3']\n",
    "    process = subprocess.check_output(args, stderr=subprocess.STDOUT)\n",
    "    metric = ((str(process, 'utf-8').splitlines())[-1]).split(' ')[-1]\n",
    "    # result = \"NDCG@10 is {}\".format(metric)\n",
    "    return metric           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the test set\n",
    "y_query_test = np.array(y_query_test)\n",
    "queryname = (y_query_test[0]).split()[1]\n",
    "test_data = []\n",
    "test_y_query = []\n",
    "test_Query = []\n",
    "q_d_len = []\n",
    "j = 0\n",
    "for i in range(X_test.shape[0]):    \n",
    "    if (y_query_test[i]).split()[1] != queryname:\n",
    "        test_data.append(X_test[j:i])\n",
    "        test_y_query.append(y_query_test[j:i])\n",
    "        test_Query.append(Query_test[j:i])\n",
    "        queryname = (y_query_test[i]).split()[1]\n",
    "        q_d_len.append(i - j)\n",
    "        j = i\n",
    "with open('group.txt', 'w') as f:\n",
    "    for i in range(len(q_d_len)):\n",
    "        f.write(str(q_d_len[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "def score(X):\n",
    "    A = []\n",
    "    temp_path = 'temp_data/'\n",
    "    if X.shape[0] == background_datasize :     \n",
    "        scorefile_path = temp_path + 'scorefile_shapk.txt'\n",
    "        restore_path = temp_path + 'restore_shapk.txt'\n",
    "        rewrite(X, y_query_train, Query_train, restore_path)\n",
    "        args = ['java', '-jar', 'RankLib-2.12.jar', '-rank', restore_path, '-load', model_dest,\n",
    "                '-indri', scorefile_path]\n",
    "        process = subprocess.check_output(args, stderr=subprocess.STDOUT)\n",
    "        scorefile_data = ''.join(sorted(open(scorefile_path), key=lambda s: s.split()[1],reverse=0))\n",
    "        with open(scorefile_path, 'w') as f:\n",
    "            f.write(scorefile_data)\n",
    "        with open(scorefile_path, 'r') as f:\n",
    "            for line in f:\n",
    "                A.append(float(line.split()[-2])) \n",
    "        os.remove(scorefile_path)\n",
    "        os.remove(restore_path)\n",
    "    else:          \n",
    "        scorefile_path = temp_path + 'scorefile_shapk_{}.txt'.format(tmp_test_y_query[0].split(':')[-1].split()[0])\n",
    "        restore_path = temp_path + 'restore_shapk_{}.txt'.format(tmp_test_y_query[0].split(':')[-1].split()[0])\n",
    "        rewrite(X, tmp_test_y_query, tmp_test_Query,restore_path) \n",
    "        args = ['java', '-jar', 'RankLib-2.12.jar', '-rank', restore_path, '-load', model_dest,\n",
    "                '-indri', scorefile_path]\n",
    "        process = subprocess.check_output(args, stderr=subprocess.STDOUT)\n",
    "        scorefile_data = ''.join(sorted(open(scorefile_path), key=lambda s: s.split()[1],reverse=0))\n",
    "        with open(scorefile_path, 'w') as f:\n",
    "            f.write(scorefile_data)\n",
    "        with open(scorefile_path, 'r') as f:\n",
    "            for line in f:\n",
    "                A.append(float(line.split()[-2]))   \n",
    "                \n",
    "        restore_context = open(restore_path, 'r').readlines()\n",
    "        with open(restore_path, 'w') as f:\n",
    "            for lineindex in range(len(restore_context)):\n",
    "                split = restore_context[lineindex].split()\n",
    "                split[1] = 'qid:{}'.format(tmp_test_y_query[0].split(':')[-1].split()[0])\n",
    "                newline = ''\n",
    "                for i in range(len(split)):\n",
    "                    newline+=(split[i]+' ')\n",
    "                f.write(newline+'\\n') \n",
    "    A  = np.array(A)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ramdomly get background data\n",
    "def rand_row(array,dim_needed):  \n",
    "    row_total = array.shape[0]\n",
    "    row_sequence = np.arange(row_total)\n",
    "    np.random.shuffle(row_sequence)\n",
    "    return array[row_sequence[0:dim_needed],:]\n",
    "\n",
    "def get_rankedduculist(scores):\n",
    "    duculist =np.array([i for i in range(q_d_len[query_index])]).reshape(-1,1)\n",
    "    doculist_score = np.append(duculist,scores,axis=1)\n",
    "    rankedduculist  = (doculist_score[(-doculist_score[:,-1]).argsort()])[:,0]\n",
    "    return rankedduculist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 5000 background data samples could cause slower run times. Consider using shap.kmeans(data, K) to summarize the background as K weighted samples.\n"
     ]
    }
   ],
   "source": [
    "# creat a explainer\n",
    "import shap\n",
    "background_datasize = 5000\n",
    "X_train = rand_row(X_train,background_datasize)\n",
    "explainer = shap.KernelExplainer(score, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_cover(shap_values):\n",
    "    shap_values =np.array([shap_values])\n",
    "    sumvalue = np.sum(shap_values, axis=1)\n",
    "    top_k = 5 # we select the 5_top important features\n",
    "    top_k_idx=((-sumvalue).argsort())[0][0:top_k]\n",
    "    return top_k_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scores of the samples of this query and rank them according to the scores\n",
    "def loop_query(query_index):\n",
    "    global tmp_test_data\n",
    "    global tmp_test_y_query\n",
    "    global tmp_test_Query\n",
    "    tmp_test_data =test_data[query_index]\n",
    "    tmp_test_y_query = test_y_query[query_index]\n",
    "    tmp_test_Query = test_Query[query_index]\n",
    "    scores = score(tmp_test_data).reshape(-1,1)\n",
    "    test_data_score = np.append(tmp_test_data,scores,axis=1)\n",
    "    ranked_test_data = (test_data_score[(-test_data_score[:,-1]).argsort()])[:,:-1]\n",
    "\n",
    "# ranklist before changing some features\n",
    "    #rankedduculist1 = get_rankedduculist(scores)\n",
    "    NDCG_before =evaluate()\n",
    "    query1_shap_values = explainer.shap_values(ranked_test_data[:k], nsamples=1000)\n",
    "    top_k_idx = get_set_cover(query1_shap_values)\n",
    "    features_to_change = tmp_test_data\n",
    "    features_to_change[:,top_k_idx] = 0\n",
    "    scores2= score(features_to_change).reshape(-1,1)\n",
    "    #rankedduculist2 = get_rankedduculist(scores2)\n",
    "    NDCG_after = evaluate()\n",
    "    delta_NDCG = float(NDCG_before) -  float(NDCG_after)\n",
    "    NDCG_file_name =  'NDCGdata/'+'SHAP{}_'.format(k)  + model_dest.split(\"_\")[0].split(\"/\")[-1] +'.txt'\n",
    "    delDir = \"temp_data/\"\n",
    "    os.remove(os.path.join(delDir, 'restore_shapk_{}.txt'.format(tmp_test_y_query[0].split(':')[-1].split()[0])))\n",
    "    os.remove(os.path.join(delDir, 'scorefile_shapk_{}.txt'.format(tmp_test_y_query[0].split(':')[-1].split()[0])))                     \n",
    "    with open(NDCG_file_name,'a') as NDCG_FILE:\n",
    "        NDCG_line = 'NDCG@10'+'  '+ tmp_test_y_query[0].split(':')[-1]+'  ' + 'changed feature:'+ str(top_k_idx)+'  '+'delta_NDCG ='+'  '+str(delta_NDCG)+ \"\\n\"\n",
    "        NDCG_FILE.write(NDCG_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ed008f21b84140910af825c645aecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb6a9f355974b81b40d53a7ed8564b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0d735b12bf4725a86ef0fcea394862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf40936cc334bf2886559a2c58bb996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742df67ecfac43dcb7fbe4b384754360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562231133312407e84349292efe46271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33252219515401f99abff64ce63638f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5eb0933f7424f3c90bdc4ba908b0461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5ae5df30fb4b4a83715a778ce0c162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2496540d7fde4202bd737d2268d57a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018452f4d3b2467fac7fbd677c59ae80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eeb6758826a449fa31f479a4349f5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2499487f6c346eeb616ef08bc004c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n",
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd2b573d8d74b74a42ee6e272c7bf1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acd68e01a76436590c2a29bf3d3ccc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62da8b2b5ebb47069a0bf3f5b6307547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a961d920114592a1b9982f828906cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff29e7da596401cb57b73b3abceb19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0e96694f1843a6b3daad623f27fdca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd88ee14e7e54c14aa1086e39cd28c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "with Pool(10) as p:\n",
    "    print(p.map(loop_query, [query_index for query_index in range(len(test_data))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reranking the NDCG file\n",
    "A = ''.join(sorted(open('NDCGdata/'+'SHAP{}_'.format(k)  + model_dest.split(\"_\")[0].split(\"/\")[-1] +'.txt'), key=lambda s: s.split()[1],reverse=0))\n",
    "with open('NDCGdata/'+'SHAP{}_'.format(k)  + model_dest.split(\"_\")[0].split(\"/\")[-1] +'.txt','w') as f:\n",
    "    f.write(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NDCGdata/'+'SHAP{}_'.format(k)  + model_dest.split(\"_\")[0].split(\"/\")[-1] + '.txt' ,'r+') as f:\n",
    "    B = []\n",
    "    for line in f:\n",
    "        B.append(float(line.split()[-1]))\n",
    "    average_mean = sum(B)/X_test.shape[0]\n",
    "    f.write(\"average delta NDCG: \" + str(average_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
