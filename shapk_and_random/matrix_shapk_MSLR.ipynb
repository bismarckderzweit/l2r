{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "os.chdir(os.path.expanduser('..'))\n",
    "import shap\n",
    "import scipy.stats as stats\n",
    "from multiprocessing import Pool,Process\n",
    "from utils.rerank import rerank_ndcg\n",
    "from utils.readdata import get_microsoft_data, rewrite\n",
    "from utils.separate_set import separate_set\n",
    "from utils.explainer_tools import rand_row, evaluate, get_rankedduculist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_average(NDCG_file_name):\n",
    "    \"\"\"\n",
    "    write the mean value of delta NDCG to the last line of NDCG file.\n",
    "    :param NDCG_file_name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with open( NDCG_file_name ,'r+') as f:\n",
    "        a = []\n",
    "        for line in f:\n",
    "            a.append(float(line.split()[-1]))\n",
    "        average_mean = sum(a)/len(a)\n",
    "        #f.write(\"average delta NDCG: \" + str(round(average_mean,4)))\n",
    "    return round(average_mean,7)\n",
    "    #return average_mean\n",
    "\n",
    "\n",
    "def write_tau(NDCG_file_name):\n",
    "    with open( NDCG_file_name ,'r+') as f:\n",
    "        a = []\n",
    "        for line in f:\n",
    "            if len(line.split())< 10 or  str(line.split('kendalltau=')[-1].split()[0])== 'nan' :\n",
    "                break\n",
    "            else:\n",
    "                a.append(float(line.split('kendalltau=')[-1].split()[0]))\n",
    "        average_mean = sum(a)/len(a)\n",
    "        #f.write(\"average tau: \" + str(round(average_mean,4)))\n",
    "    return round(average_mean,7)  \n",
    "    #return average_mean\n",
    "\n",
    "\n",
    "\n",
    "def write_ratio(NDCG_file_name):\n",
    "    with open( NDCG_file_name ,'r+') as f:\n",
    "        a = []\n",
    "        for line in f:\n",
    "            if len(line.split())< 10:\n",
    "                break\n",
    "            else:\n",
    "                a.append(float(line.split('ratioNDCG:')[-1].split()[0]))\n",
    "        average_mean = sum(a)/len(a)\n",
    "    return round(average_mean,7)\n",
    "    #return average_mean\n",
    "\n",
    "def get_set_cover(shap_values):\n",
    "\n",
    "    shap_values =np.array([shap_values])\n",
    "    #shap_values[shap_values < 0] = 0\n",
    "    sumvalue = np.sum(shap_values,axis=1)\n",
    "    shap_values_std = np.std(shap_values,ddof=1, axis=1)\n",
    "    top_k = 10\n",
    "    top_k_idx=((-sumvalue).argsort())[0][0:top_k]\n",
    "    return top_k_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(X):\n",
    "    \"\"\"\n",
    "    The first if branch is training data, the next is for the single test data. First calling the subprocess of ranklib\n",
    "    to get the scores, then rerank the scorefile according the original index. We also have to delete the produced\n",
    "    files which used by the subprocess.\n",
    "    :param X: input feature matrix\n",
    "    :return: scores of q-d pairs\n",
    "    \"\"\"\n",
    "    A = []\n",
    "    if X.shape[0] == background_datasize:\n",
    "        # this part is for the training\n",
    "        scorefile_path = temp_path + 'scorefile_shapk.txt'\n",
    "        restore_path = temp_path + 'restore_shapk.txt'\n",
    "        rewrite(X, y_query_train, Query_train, restore_path)\n",
    "        args = ['java', '-jar', 'RankLib-2.12.jar', '-rank', restore_path, '-load', model,\n",
    "                '-indri', scorefile_path]\n",
    "        subprocess.check_output(args, stderr=subprocess.STDOUT,timeout=5000)\n",
    "\n",
    "        # rerank the scorefile according the original index\n",
    "        scorefile_data = ''.join(sorted(open(scorefile_path), key=lambda s: s.split()[1], reverse=False))\n",
    "        with open(scorefile_path, 'w') as f:\n",
    "            f.write(scorefile_data)\n",
    "\n",
    "        # get the scores\n",
    "        with open(scorefile_path, 'r') as f:\n",
    "            for line in f:\n",
    "                A.append(float(line.split()[-2]))\n",
    "        os.remove(scorefile_path)\n",
    "        os.remove(restore_path)\n",
    "    else:\n",
    "        # this part is for getting shapley values\n",
    "        scorefile_path = temp_path + 'scorefile_shapk_{}.txt'.format(tmp_test_y_query[0].split(':')[-1].split()[0])\n",
    "        restore_path = temp_path + 'restore_shapk_{}.txt'.format(tmp_test_y_query[0].split(':')[-1].split()[0])\n",
    "        rewrite(X, tmp_test_y_query, tmp_test_Query, restore_path)\n",
    "        args = ['java', '-jar', 'RankLib-2.12.jar', '-rank', restore_path, '-load', model,\n",
    "                '-indri', scorefile_path]\n",
    "        subprocess.check_output(args, stderr=subprocess.STDOUT, timeout=5000)  \n",
    "\n",
    "        # rerank the scorefile according the original index\n",
    "        scorefile_data = ''.join(sorted(open(scorefile_path), key=lambda s: s.split()[1], reverse=False))\n",
    "        with open(scorefile_path, 'w') as f:\n",
    "            f.write(scorefile_data)\n",
    "        with open(scorefile_path, 'r') as f:\n",
    "            for line in f:\n",
    "                A.append(float(line.split()[-2]))\n",
    "\n",
    "        # reset the index to be original otherwise can not get the right NDCG\n",
    "        restore_context = open(restore_path, 'r').readlines()\n",
    "        with open(restore_path, 'w') as f:\n",
    "            for lineindex in range(len(restore_context)):\n",
    "                split = restore_context[lineindex].split()\n",
    "                split[1] = 'qid:{}'.format(tmp_test_y_query[0].split(':')[-1].split()[0])\n",
    "                newline = ''\n",
    "                for i in range(len(split)):\n",
    "                    newline += (split[i] + ' ')\n",
    "                f.write(newline + '\\n')\n",
    "\n",
    "    A = np.array(A)\n",
    "    return A\n",
    "\n",
    "\n",
    "def loop_query(query_index):\n",
    "    \"\"\"\n",
    "    loop for a query, get scores of the samples of this query and rank them according to the scores\n",
    "    :param query_index: the index of query\n",
    "    :return: ranklist file, delta NDCG file\n",
    "    \"\"\"\n",
    "    # get data for this query\n",
    "    global tmp_test_data\n",
    "    global tmp_test_y_query\n",
    "    global tmp_test_Query\n",
    "    tmp_test_data =test_data[query_index]\n",
    "    tmp_test_y_query = test_y_query[query_index]\n",
    "    tmp_test_Query = test_Query[query_index]\n",
    "    query_id = tmp_test_y_query[0].split(':')[-1].split()[0]\n",
    "\n",
    "    # calculate the scores for the q-d pairs\n",
    "    scores = score(tmp_test_data).reshape(-1,1)\n",
    "    restore_path = temp_path + 'restore_shapk_{}.txt'.format(query_id)\n",
    "    scorefile_path = temp_path + 'scorefile_shapk_{}.txt'.format(query_id)\n",
    "\n",
    "    # reranking the test_data according to the scores and get the list of ranking\n",
    "    test_data_score = np.append(tmp_test_data,scores,axis=1)\n",
    "    ranked_test_data = (test_data_score[(-test_data_score[:,-1]).argsort()])[:,:-1]\n",
    "    rankedduculist1 = get_rankedduculist(scores, query_index,q_d_len)\n",
    "    NDCG_before =evaluate(model,restore_path)\n",
    "\n",
    "\n",
    "    query1_shap_values = explainer.shap_values(ranked_test_data[:k], nsamples=200)\n",
    "\n",
    "    # get top 10 features and set them to 0\n",
    "    \n",
    "    top_k_idx  = get_set_cover(query1_shap_values)\n",
    "    def feature_k_loop(feature_number,threshold_flag):\n",
    "        \n",
    "        NDCG_file_name = NDCGdata_path + '{}_SHAP{}_{}features_threshold{}'.format(dataname,k,feature_number, threshold_flag) + modelname + '.txt'\n",
    "        ranklist_file = NDCGdata_path + '{}_ranklist_SHAP{}_{}features_threshold{}'.format(dataname,k,feature_number, threshold_flag) + modelname + '.txt'\n",
    "        features_to_change = tmp_test_data.copy()\n",
    "        if len(top_k_idx)<= feature_number:\n",
    "            feature_number = len(top_k_idx)\n",
    "        features_to_change[:,top_k_idx[0:feature_number]] = expected_value[top_k_idx[0:feature_number]]\n",
    "        # get scores of the changed features\n",
    "        scores2 = score(features_to_change).reshape(-1,1)\n",
    "        NDCG_after = evaluate(model,restore_path)\n",
    "        delta_NDCG = abs(float(NDCG_before) - float(NDCG_after))\n",
    "        if float(NDCG_before)  == 0:\n",
    "            ratio_NDCG = 0\n",
    "        else:\n",
    "            ratio_NDCG = delta_NDCG/float(NDCG_before) \n",
    "            \n",
    "        rankedduculist2 = get_rankedduculist(scores2, query_index,q_d_len)\n",
    "        tau, p_value = stats.kendalltau(rankedduculist1, rankedduculist2)\n",
    "        os.remove(scorefile_path)\n",
    "        os.remove(restore_path)\n",
    "        with open(NDCG_file_name,'a') as NDCG_FILE:\n",
    "            NDCG_line = tmp_test_y_query[0].split(':')[-1]+'  ' + \\\n",
    "                        'changed feature:'+ str(top_k_idx[0:feature_number])+'  '+'kendalltau='+str(round(tau,4))+ '  '+'ratioNDCG:'+ str(round(ratio_NDCG,4))+'  '+'delta_NDCG ='+'  '+str(delta_NDCG)+\"\\n\"\n",
    "            NDCG_FILE.write(NDCG_line)\n",
    "        with open(ranklist_file, 'a') as ranklist:\n",
    "            ranklist_line = tmp_test_y_query[0].split(':')[-1] + '  ' + 'ranklist before:' + str(\n",
    "                rankedduculist1) + '  ' + 'ranklist after:' + '  ' + str(rankedduculist2) + \"\\n\"\n",
    "            ranklist.write(ranklist_line)\n",
    "                   \n",
    "    for threshold_flag in threshold:\n",
    "        feature_k_loop(5,threshold_flag)        \n",
    "        feature_k_loop(10,threshold_flag)\n",
    "    all_features = [i for i in range(136)]\n",
    "    complement_idx = list(set(all_features) - set(top_k_idx[:5]))\n",
    "    complement_NDCG_file_name = NDCGdata_path + '{}_SHAP{}_complement'.format(dataname,k) + modelname + '.txt'\n",
    "    complement_ranklist_file = NDCGdata_path + '{}_ranklist_SHAP{}_complement'.format(dataname,k) + modelname + '.txt'\n",
    "    features_to_change = tmp_test_data.copy()\n",
    "    features_to_change[:,complement_idx] = expected_value[complement_idx]\n",
    "    scores3 = score(features_to_change).reshape(-1,1)\n",
    "    rankedduculist3 = get_rankedduculist(scores3, query_index, q_d_len)\n",
    "    NDCG_after2 = evaluate(model, restore_path)\n",
    "    delta_NDCG2 = abs(float(NDCG_before) - float(NDCG_after2))\n",
    "    if float(NDCG_before)  == 0:\n",
    "        ratio_NDCG2 = 0\n",
    "    else:\n",
    "        ratio_NDCG2 = delta_NDCG2/float(NDCG_before) \n",
    "    tau2, p_value2 = stats.kendalltau(rankedduculist1, rankedduculist3)\n",
    "\n",
    "    with open(complement_NDCG_file_name, 'a') as NDCG_FILE:\n",
    "        NDCG_line =  tmp_test_y_query[0].split(':')[-1]+'  ' \\\n",
    "                    + 'changed feature:'+ str(complement_idx)+' '+'kendalltau='+str(round(tau2,4)) + '  '+'ratioNDCG:'+ str(round(ratio_NDCG2,4))+ '  ' + \\\n",
    "                    '   ' + 'delta_NDCG ='+'  '+str(round(delta_NDCG2,4))+ \"\\n\"\n",
    "        NDCG_FILE.write(NDCG_line)\n",
    "    \n",
    "    with open(complement_ranklist_file, 'a') as ranklist:\n",
    "        ranklist_line = tmp_test_y_query[0].split(':')[-1] + '  ' + 'ranklist before:' + str(\n",
    "            rankedduculist1) + '  ' + 'ranklist after:' + '  ' + str(rankedduculist3) + \"\\n\"\n",
    "        ranklist.write(ranklist_line)\n",
    "    os.remove(scorefile_path)\n",
    "    os.remove(restore_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    #parameters to be set\n",
    "    model_path = 'MSLR-WEB10K_model/'\n",
    "    model_set =['RankBoost_model.txt']\n",
    "    #model_set = ['LambdaMART_model.txt','Listnet_model.txt','LinearRegression_model.txt','coordinateascent_model.txt','Randomforests_model.txt']\n",
    "    for MODEL in model_set:\n",
    "        model = model_path + MODEL\n",
    "        k_set = [5]  # k: shap k, we select the top kexample to do analysis\n",
    "        threshold = [0]  \n",
    "\n",
    "        for f in range(1,2):\n",
    "        # the path of data\n",
    "        #datapath = 'MQ2008/Fold1/'\n",
    "            #datapath = 'MQ2008/Fold{}/'.format(f)\n",
    "            datapath = 'MSLR-WEB10K/Fold{}/'.format(f)\n",
    "            train_path = datapath + 'train.txt'\n",
    "            test_path = datapath + 'test.txt'\n",
    "            modelname = model.split(\"_\")[1].split(\"/\")[-1]\n",
    "            dataname = datapath.split('/')[0] +'_'+ datapath.split('/')[1].split('Fold')[1]\n",
    "\n",
    "            # saving path and save files\n",
    "            NDCGdata_path = 'logs/'\n",
    "            temp_path = 'temp_file/'\n",
    "\n",
    "\n",
    "            # get train data and test data\n",
    "            X_train, y_query_train, Query_train = get_microsoft_data(train_path)\n",
    "            X_train = np.array(X_train)\n",
    "            X_test, y_query_test, Query_test = get_microsoft_data(test_path)\n",
    "            X_test = np.array(X_test)\n",
    "            expected_value = np.mean(X_train, axis=0)\n",
    "\n",
    "            # separate the test set\n",
    "            test_data, test_y_query, test_Query, q_d_len = separate_set(y_query_test, X_test, Query_test)\n",
    "\n",
    "            # creat a explainer\n",
    "            background_datasize = 500\n",
    "            X_train = rand_row(X_train,background_datasize)\n",
    "            explainer = shap.KernelExplainer(score, X_train)\n",
    "\n",
    "            resultfile_NDCG = 'resultfile/' + '{}_{}_shapk_NDCG.txt'.format(dataname,modelname)\n",
    "            resultfile_tau = 'resultfile/' + '{}_{}_shapk_tau.txt'.format(dataname,modelname)\n",
    "            resultfile_ratio =  'resultfile/' + '{}_{}_shapk_ratio.txt'.format(dataname,modelname)\n",
    "\n",
    "            for k in k_set:\n",
    "                complement_resultfile_NDCG = 'resultfile/' + '{}_{}_shapk{}_complement_NDCG.txt'.format(dataname,modelname,k)\n",
    "                complement_resultfile_tau = 'resultfile/' + '{}_{}_shapk{}_complement_tau.txt'.format(dataname,modelname,k)\n",
    "                complement_resultfile_ratio =  'resultfile/' + '{}_{}_shapk{}_complement_ratio.txt'.format(dataname,modelname,k)\n",
    "               \n",
    "                with Pool(25) as p:\n",
    "                    print(p.map(loop_query, [query_index for query_index in range(600)])) \n",
    "                for threshold_flag in threshold:\n",
    "                    for feature_number in (5,10):\n",
    "                        NDCG_file_name = NDCGdata_path + '{}_SHAP{}_{}features_threshold{}'.format(dataname,k,feature_number, threshold_flag) + modelname + '.txt'\n",
    "                        ranklist_file = NDCGdata_path + '{}_ranklist_SHAP{}_{}features_threshold{}'.format(dataname,k,feature_number, threshold_flag) + modelname + '.txt'\n",
    "                        complement_NDCG_file_name = NDCGdata_path + '{}_SHAP{}_complement'.format(dataname,k) + modelname + '.txt'\n",
    "                        complement_ranklist_file = NDCGdata_path + '{}_ranklist_SHAP{}_complement'.format(dataname,k) + modelname + '.txt'\n",
    "                        rerank_ndcg(NDCG_file_name)\n",
    "                        rerank_ndcg(ranklist_file)\n",
    "                        tau = write_tau(NDCG_file_name)\n",
    "                        NDCG = write_average(NDCG_file_name)\n",
    "                        ratio = write_ratio(NDCG_file_name)\n",
    "                        with open(resultfile_NDCG,'a') as NDCG_result:\n",
    "                            NDCG_result_line  = str(NDCG) + \"\\n\"\n",
    "                            NDCG_result.write(NDCG_result_line)\n",
    "                        with open(resultfile_tau,'a') as tau_result:\n",
    "                            tau_result_line  = str(tau) + \"\\n\" \n",
    "                            tau_result.write(tau_result_line)\n",
    "                        with open(resultfile_ratio,'a') as ratio_result:\n",
    "                            ratio_result_line  = str(ratio) + \"\\n\" \n",
    "                            ratio_result.write(ratio_result_line)  \n",
    "                    rerank_ndcg(complement_NDCG_file_name)\n",
    "                    rerank_ndcg(complement_ranklist_file)\n",
    "                    tau = write_tau(complement_NDCG_file_name)\n",
    "                    NDCG = write_average(complement_NDCG_file_name)\n",
    "                    ratio = write_ratio(complement_NDCG_file_name)\n",
    "                    with open(complement_resultfile_NDCG,'a') as NDCG_result:\n",
    "                        NDCG_result_line  = str(NDCG) + \"\\n\"\n",
    "                        NDCG_result.write(NDCG_result_line)\n",
    "                    with open(complement_resultfile_tau,'a') as tau_result:\n",
    "                        tau_result_line  = str(tau) + \"\\n\" \n",
    "                        tau_result.write(tau_result_line)\n",
    "                    with open(complement_resultfile_ratio,'a') as ratio_result:\n",
    "                        ratio_result_line  = str(ratio) + \"\\n\" \n",
    "                        ratio_result.write(ratio_result_line)                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'MSLR-WEB10K_model/'\n",
    "model_set =['LambdaMART_model.txt','RankBoost_model.txt']\n",
    "#model_set = ['LambdaMART_model.txt','Listnet_model.txt','LinearRegression_model.txt','coordinateascent_model.txt','Randomforests_model.txt']\n",
    "for MODEL in model_set:\n",
    "    model = model_path + MODEL\n",
    "    k_set = [5]  # k: shap k, we select the top kexample to do analysis\n",
    "    threshold = [0]  \n",
    "\n",
    "    for f in range(1,2):\n",
    "\n",
    "        datapath = 'MSLR-WEB10K/Fold{}/'.format(f)\n",
    "        train_path = datapath + 'train.txt'\n",
    "        test_path = datapath + 'test.txt'\n",
    "        modelname = model.split(\"_\")[1].split(\"/\")[-1]\n",
    "        dataname = datapath.split('/')[0] +'_'+ datapath.split('/')[1].split('Fold')[1]\n",
    "\n",
    "        # saving path and save files\n",
    "        NDCGdata_path = 'F3/shap_1000/'\n",
    "\n",
    "\n",
    "\n",
    "        resultfile_NDCG = 'resultfile/' + '{}_{}_shapk_NDCG.txt'.format(dataname,modelname)\n",
    "        resultfile_tau = 'resultfile/' + '{}_{}_shapk_tau.txt'.format(dataname,modelname)\n",
    "        resultfile_ratio =  'resultfile/' + '{}_{}_shapk_ratio.txt'.format(dataname,modelname)\n",
    "\n",
    "        for k in k_set:\n",
    "            complement_resultfile_NDCG = 'resultfile/' + '{}_{}_shapk{}_complement_NDCG.txt'.format(dataname,modelname,k)\n",
    "            complement_resultfile_tau = 'resultfile/' + '{}_{}_shapk{}_complement_tau.txt'.format(dataname,modelname,k)\n",
    "            complement_resultfile_ratio =  'resultfile/' + '{}_{}_shapk{}_complement_ratio.txt'.format(dataname,modelname,k)\n",
    "\n",
    "\n",
    "            for threshold_flag in threshold:\n",
    "                for feature_number in (5,10):\n",
    "                    NDCG_file_name = NDCGdata_path + '{}_SHAP{}_{}features_threshold{}'.format(dataname,k,feature_number, threshold_flag) + modelname + '.txt'\n",
    "                    ranklist_file = NDCGdata_path + '{}_ranklist_SHAP{}_{}features_threshold{}'.format(dataname,k,feature_number, threshold_flag) + modelname + '.txt'\n",
    "                    complement_NDCG_file_name = NDCGdata_path + '{}_SHAP{}_complement'.format(dataname,k) + modelname + '.txt'\n",
    "                    complement_ranklist_file = NDCGdata_path + '{}_ranklist_SHAP{}_complement'.format(dataname,k) + modelname + '.txt'\n",
    "                    rerank_ndcg(NDCG_file_name)\n",
    "                    #rerank_ndcg(ranklist_file)\n",
    "                    tau = write_tau(NDCG_file_name)\n",
    "                    NDCG = write_average(NDCG_file_name)\n",
    "                    ratio = write_ratio(NDCG_file_name)\n",
    "                    with open(resultfile_NDCG,'a') as NDCG_result:\n",
    "                        NDCG_result_line  = str(NDCG) + \"\\n\"\n",
    "                        NDCG_result.write(NDCG_result_line)\n",
    "                    with open(resultfile_tau,'a') as tau_result:\n",
    "                        tau_result_line  = str(tau) + \"\\n\" \n",
    "                        tau_result.write(tau_result_line)\n",
    "                    with open(resultfile_ratio,'a') as ratio_result:\n",
    "                        ratio_result_line  = str(ratio) + \"\\n\" \n",
    "                        ratio_result.write(ratio_result_line)  \n",
    "                rerank_ndcg(complement_NDCG_file_name)\n",
    "                #rerank_ndcg(complement_ranklist_file)\n",
    "                tau = write_tau(complement_NDCG_file_name)\n",
    "                NDCG = write_average(complement_NDCG_file_name)\n",
    "                ratio = write_ratio(complement_NDCG_file_name)\n",
    "                with open(complement_resultfile_NDCG,'a') as NDCG_result:\n",
    "                    NDCG_result_line  = str(NDCG) + \"\\n\"\n",
    "                    NDCG_result.write(NDCG_result_line)\n",
    "                with open(complement_resultfile_tau,'a') as tau_result:\n",
    "                    tau_result_line  = str(tau) + \"\\n\" \n",
    "                    tau_result.write(tau_result_line)\n",
    "                with open(complement_resultfile_ratio,'a') as ratio_result:\n",
    "                    ratio_result_line  = str(ratio) + \"\\n\" \n",
    "                    ratio_result.write(ratio_result_line)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
