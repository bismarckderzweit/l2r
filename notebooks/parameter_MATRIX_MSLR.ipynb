{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "import shap\n",
    "import scipy.stats as stats\n",
    "from multiprocessing import Pool\n",
    "from utils.rerank import write_average, rerank_ndcg, rerank_matrix,write_tau,write_ratio\n",
    "from utils.readdata import get_microsoft_data, rewrite\n",
    "from utils.separate_set import separate_set\n",
    "from utils.explainer_tools import rand_row, evaluate, get_pairsname, get_rankedduculist, small_get_pairsname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_cover(shap_values, threshold_flag):\n",
    "    \"\"\"\n",
    "    get scores of the samples of this query and rank them according to the scores,\n",
    "    we select the 10_top important features\n",
    "    :param shap_values:\n",
    "    :param threshold_flag: 0: simple sum, 1: set the threshold to be 2 means, 2: mean - 3*shap_values_std\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    shap_values =np.array([shap_values])\n",
    "    # shap_values[shap_values < 0] = 0\n",
    "    sumvalue = np.sum(shap_values,axis=1)\n",
    "    mean =  sumvalue/shap_values.shape[1]\n",
    "    shap_values_std = np.std(shap_values,ddof=1, axis=1)\n",
    "    top_k = 10\n",
    "    temp_shap = shap_values[0].copy()\n",
    "    for x in range(0, temp_shap.shape[0]):\n",
    "        for y in range(0, temp_shap.shape[1]):\n",
    "            if temp_shap[x,y] <= 0:\n",
    "                temp_shap[x,y] = 0\n",
    "    sumpositive = np.sum(temp_shap, axis=0)\n",
    "    positive_mean = sumpositive/len(shap_values)\n",
    "    if threshold_flag == 0:\n",
    "        top_k_idx=((-sumvalue).argsort())[0][0:top_k]\n",
    "        return top_k_idx, mean\n",
    "    elif threshold_flag== 1:\n",
    "        threshold = 2*mean\n",
    "    elif threshold_flag== 2:\n",
    "        threshold = mean - 3*shap_values_std\n",
    "    elif threshold_flag==3:\n",
    "        threshold = 15*mean\n",
    "    elif threshold_flag ==4:\n",
    "        threshold = [[0 for i in range(shap_values.shape[2])]]\n",
    "    elif threshold_flag ==5:\n",
    "        threshold = [positive_mean*0.5]\n",
    "    top_k_idx = []\n",
    "    for i in range(top_k):\n",
    "        feature_index=((-sumvalue).argsort())[0][0]\n",
    "        top_k_idx.append(feature_index)\n",
    "        bigindex = list(np.where(shap_values[0][:,feature_index]>threshold[0][feature_index]))\n",
    "        shap_values[0][:,feature_index] = 0\n",
    "        shap_values[0][bigindex] = 0\n",
    "        sumvalue = np.sum(shap_values, axis=1)\n",
    "        if np.all(sumvalue == 0): break\n",
    "    return top_k_idx, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(X):\n",
    "    \"\"\"\n",
    "    The first if branch is training data, the next is for the single test data. First calling the subprocess of ranklib\n",
    "    to get the scores, then rerank the scorefile according the original index. We also have to delete the produced\n",
    "    files which used by the subprocess.\n",
    "    :param X: input feature matrix\n",
    "    :return: scores of q-d pairs\n",
    "    \"\"\"\n",
    "    A = []\n",
    "    scorefile_path = temp_path + 'scorefile_MATRIX_{}.txt'.format(tmp_test_y_query[0].split(':')[-1].split()[0])\n",
    "    restore_path = temp_path + 'restore_MATRIX_{}.txt'.format(tmp_test_y_query[0].split(':')[-1].split()[0])\n",
    "    rewrite(X, tmp_test_y_query, tmp_test_Query, restore_path)\n",
    "    args = ['java', '-jar', 'RankLib-2.12.jar', '-rank', restore_path, '-load', model,\n",
    "            '-indri', scorefile_path]\n",
    "    subprocess.check_output(args, stderr=subprocess.STDOUT, timeout = 20000)\n",
    "\n",
    "    # rerank the scorefile according the original index\n",
    "    scorefile_data = ''.join(sorted(open(scorefile_path), key=lambda s: s.split()[1], reverse=False))\n",
    "    with open(scorefile_path, 'w') as f:\n",
    "        f.write(scorefile_data)\n",
    "    with open(scorefile_path, 'r') as f:\n",
    "        for line in f:\n",
    "            A.append(float(line.split()[-2]))\n",
    "\n",
    "    # reset the index to be original otherwise can not get the right NDCG\n",
    "    restore_context = open(restore_path, 'r').readlines()\n",
    "    with open(restore_path, 'w') as f:\n",
    "        for lineindex in range(len(restore_context)):\n",
    "            split = restore_context[lineindex].split()\n",
    "            split[1] = 'qid:{}'.format(tmp_test_y_query[0].split(':')[-1].split()[0])\n",
    "            newline = ''\n",
    "            for i in range(len(split)):\n",
    "                newline += (split[i] + ' ')\n",
    "            f.write(newline + '\\n')\n",
    "    A = np.array(A)\n",
    "    return A\n",
    "\n",
    "\n",
    "def loop_query(query_index):\n",
    "    \"\"\"\n",
    "    loop for a query, get scores of the samples of this query and rank them according to the scores\n",
    "    :param query_index: the index of query\n",
    "    :return: ranklist file, matrix file, delta NDCG file\n",
    "    \"\"\"\n",
    "    # get data for this query\n",
    "    global tmp_test_data\n",
    "    global tmp_test_y_query\n",
    "    global tmp_test_Query\n",
    "    tmp_test_data =test_data[query_index]\n",
    "    tmp_test_y_query = test_y_query[query_index]\n",
    "    tmp_test_Query = test_Query[query_index]\n",
    "    query_id = tmp_test_y_query[0].split(':')[-1].split()[0]\n",
    "\n",
    "    # calculate the scores for the q-d pairs\n",
    "    restore_path = temp_path +  'restore_MATRIX_{}.txt'.format(query_id)\n",
    "    scorefile_path = temp_path + 'scorefile_MATRIX_{}.txt'.format(query_id)\n",
    "    scores = score(tmp_test_data).reshape(-1, 1)\n",
    "    sorted_scores = scores\n",
    "    sorted_scores = sorted(sorted_scores.reshape(1, -1)[0].tolist(),reverse = True)\n",
    "\n",
    "    # reranking the test_data according to the scores and get the list of ranking\n",
    "    test_data_score = np.append(tmp_test_data,scores,axis=1)\n",
    "    ranked_test_data = np.array((test_data_score[(-test_data_score[:,-1]).argsort()])[:,:-1])\n",
    "    rankedduculist1 = get_rankedduculist(scores, query_index, q_d_len)\n",
    "    NDCG_before = evaluate(model, restore_path)\n",
    "\n",
    "    # get pairsname\n",
    "    global pairsname\n",
    "    if q_d_len[query_index] >= 15:\n",
    "        pairnumbers = 100\n",
    "        pairsname = get_pairsname(ranked_test_data, pairnumbers)\n",
    "    else:\n",
    "        pairsname = small_get_pairsname(ranked_test_data)\n",
    "        \n",
    "\n",
    "    def get_score_matrix(feature_matrix):\n",
    "        changed_list = []\n",
    "        for i in range(feature_matrix.shape[0]):\n",
    "            temp =  feature_matrix[i].copy()\n",
    "            for m in range(tmp_test_data.shape[1]):\n",
    "                temp2 = temp.copy()\n",
    "                temp2[m] = expected_value[m]\n",
    "                changed_list.append(temp2)\n",
    "        changed_list = np.array(changed_list)\n",
    "        with open(temp_path+'changed_list_MATRIX{}.txt'.format(query_index),'w') as f:\n",
    "            for i in range(feature_matrix.shape[0]*X_test.shape[1]):\n",
    "                line = \"\"\n",
    "                line += \"0 qid:{} \".format(str(i))\n",
    "                for j in range(len(changed_list[i])):\n",
    "                    line += ((str(j+1))+\":\"+str(changed_list[i][j])+\" \")\n",
    "                line += '#docid = GX008-86-4444840 inc = 1 prob = 0.086622 ' + \"\\n\"\n",
    "                f.write(line)\n",
    "        args = ['java', '-jar', 'RankLib-2.12.jar', '-rank', temp_path+'changed_list_MATRIX{}.txt'.format(query_index), '-load', model,\n",
    "                '-indri', temp_path+'changed_list_MATRIX_score{}.txt'.format(query_index)]\n",
    "        subprocess.check_output(args, stderr=subprocess.STDOUT, timeout = 20000)\n",
    "        A = ''.join(sorted(open(temp_path+'changed_list_MATRIX_score{}.txt'.format(query_index)), key=lambda s: int(s.split()[0]), reverse=False))\n",
    "        with open(temp_path+'changed_list_MATRIX_score{}.txt'.format(query_index),'w') as f:\n",
    "            f.write(A)\n",
    "        changed_list_score = []\n",
    "        with open(temp_path+'changed_list_MATRIX_score{}.txt'.format(query_index),'r') as f:\n",
    "            for line in f:\n",
    "                changed_list_score.append(float(line.split()[-2]))\n",
    "        changed_list_score =  [changed_list_score[i:i + tmp_test_data.shape[1]] for i in range(0, len(changed_list_score), tmp_test_data.shape[1])]   \n",
    "        os.remove(os.path.join(temp_path, 'changed_list_MATRIX{}.txt'.format(query_index)))\n",
    "        os.remove(os.path.join(temp_path, 'changed_list_MATRIX_score{}.txt'.format(query_index))) \n",
    "        return changed_list_score\n",
    "        \n",
    "    # create the matrix\n",
    "    def get_matrix(ranked_test_data):\n",
    "        score_values = get_score_matrix(ranked_test_data)\n",
    "        matrix = []\n",
    "        for i in range(len(pairsname)):\n",
    "            index1 = int(pairsname[i][1])\n",
    "            index2 = int(pairsname[i][-1])\n",
    "            #row = [(sorted_scores[index1-1]-sorted_scores[index2-1]-score_values[index1-1][j] + score_values[index2-1][j])*(index2 - index1) for j in range(tmp_test_data.shape[1])]\n",
    "            row = [round((score_values[index2-1][j] - score_values[index1-1][j]),4) for j in range(tmp_test_data.shape[1])]\n",
    "            #row = [(score_values[index2-1][j] - score_values[index1-1][j])*(index2 - index1) for j in range(tmp_test_data.shape[1])]\n",
    "            matrix.append(row)\n",
    "        \"\"\"\n",
    "        for i in range(len(matrix)):\n",
    "            for j in range(len(matrix[0])):\n",
    "                if matrix[i][j] >=0:\n",
    "                    matrix[i][j] = 1\n",
    "                else:\n",
    "                    matrix[i][j] = -1\n",
    "        \"\"\"  \n",
    "        return matrix   \n",
    "\n",
    "    def feature_k_loop(feature_number,threshold_flag):\n",
    "        NDCG_file_name = NDCGdata_path + '{}_MATRIX_{}features_threshold{}'.format(dataname,feature_number,threshold_flag) + modelname + '.txt'\n",
    "        NDCG_file_matrix = NDCGdata_path + '{}_MATRIX_matrix_{}features_threshold{}'.format(dataname,feature_number,threshold_flag)  + modelname + '.txt'\n",
    "        ranklist_file = NDCGdata_path + '{}_ranklist_MATRIX_{}features_threshold{}'.format(dataname,feature_number,threshold_flag)  + modelname + '.txt'\n",
    "        top_k_idx = []\n",
    "        temp_ranked_test_data = ranked_test_data\n",
    "        matrix  = get_matrix(temp_ranked_test_data)\n",
    "        top_k_idx_temp,_ = get_set_cover(matrix, threshold_flag)\n",
    "        temp_index = top_k_idx_temp[0]\n",
    "        top_k_idx.append(temp_index)\n",
    "        temp_tmp_test_data = tmp_test_data\n",
    "        for i in range(9):\n",
    "            temp_tmp_test_data[:,temp_index] = expected_value[temp_index]\n",
    "            scores_temp = score(temp_tmp_test_data).reshape(-1,1)\n",
    "            rankedduculist_temp = get_rankedduculist(scores_temp, query_index, q_d_len)\n",
    "            changedpairs = []\n",
    "            for i in range(len(rankedduculist1)-1):\n",
    "                for j in range(i+1,len(rankedduculist1)):\n",
    "                    doc1 = rankedduculist1[i]\n",
    "                    doc2 = rankedduculist1[j]\n",
    "                    if rankedduculist_temp.index(doc1) > rankedduculist_temp.index(doc2):\n",
    "                        changedpairs.append([i,j])      \n",
    "\n",
    "            for i in range(len(changedpairs)):\n",
    "                if len(pairsname)<=1:break\n",
    "                deletedpair = 'd' + str(changedpairs[i][0])+'>d'+ str(changedpairs[i][1])\n",
    "                if deletedpair in pairsname:\n",
    "                    pairsname.remove(deletedpair)\n",
    "                    \n",
    "            temp_ranked_test_data[:,temp_index] = expected_value[temp_index]\n",
    "            matrix  = get_matrix(temp_ranked_test_data)\n",
    "            top_k_idx_temp,_ = get_set_cover(matrix, threshold_flag)\n",
    "            for i in range(len(top_k_idx_temp)):\n",
    "                if top_k_idx_temp[i] in top_k_idx:continue\n",
    "                else:\n",
    "                    temp_index = top_k_idx_temp[i]    \n",
    "            top_k_idx.append(temp_index)\n",
    "            with open(NDCG_file_matrix, 'a') as matrix_FILE:\n",
    "                matrix_line = 'matrix for {}'.format(tmp_test_y_query[0].split(':')[-1].split()[0]) \\\n",
    "                        + '  ' + str(matrix) + '  ' + \"\\n\"\n",
    "                matrix_FILE.write(matrix_line)\n",
    "        \n",
    "        features_to_change = tmp_test_data\n",
    "        if len(top_k_idx)<= feature_number:\n",
    "            feature_number = len(top_k_idx)\n",
    "        features_to_change[:,top_k_idx[0:feature_number]] = expected_value[top_k_idx[0:feature_number]]\n",
    "        restore_path = temp_path +  'restore_MATRIX_{}.txt'.format(query_id,feature_number)\n",
    "        scorefile_path = temp_path + 'scorefile_MATRIX_{}.txt'.format(query_id,feature_number)\n",
    "        # get scores of the changed features\n",
    "        scores2 = score(features_to_change).reshape(-1,1)\n",
    "        rankedduculist2 = get_rankedduculist(scores2, query_index, q_d_len)\n",
    "        NDCG_after = evaluate(model, restore_path)\n",
    "        delta_NDCG = abs(float(NDCG_before) - float(NDCG_after))\n",
    "        if float(NDCG_before)  == 0:\n",
    "            ratio_NDCG = 0\n",
    "        else:\n",
    "            ratio_NDCG = delta_NDCG/float(NDCG_before) \n",
    "        tau, p_value = stats.kendalltau(rankedduculist1, rankedduculist2)\n",
    "  \n",
    "        with open(NDCG_file_name, 'a') as NDCG_FILE:\n",
    "            NDCG_line =  tmp_test_y_query[0].split(':')[-1]+'  ' \\\n",
    "                        + 'changed feature:'+ str(top_k_idx[0:feature_number])+' '+'kendalltau='+str(round(tau,4)) + '  '+'ratioNDCG:'+ str(round(ratio_NDCG,4))+ '  ' + 'pairnames:'+' '+str(pairsname) + \\\n",
    "                        '   ' + 'delta_NDCG ='+'  '+str(round(delta_NDCG,4))+ \"\\n\"\n",
    "            NDCG_FILE.write(NDCG_line)\n",
    "        with open(NDCG_file_matrix, 'a') as matrix_FILE:\n",
    "            matrix_line = 'matrix for {}'.format(tmp_test_y_query[0].split(':')[-1].split()[0]) \\\n",
    "                          + '  ' + str(matrix) + '  ' + \"\\n\"\n",
    "            matrix_FILE.write(matrix_line)\n",
    "        with open(ranklist_file, 'a') as ranklist:\n",
    "            ranklist_line = tmp_test_y_query[0].split(':')[-1] + '  ' + 'ranklist before:' + str(\n",
    "                rankedduculist1) + '  ' + 'ranklist after:' + '  ' + str(rankedduculist2) + \"\\n\"\n",
    "            ranklist.write(ranklist_line)\n",
    "        os.remove(scorefile_path)\n",
    "        os.remove(restore_path)\n",
    "             \n",
    "    feature_k_loop(5,threshold_flag)        \n",
    "    feature_k_loop(10,threshold_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    #parameters to be set\n",
    "    model_path = 'MSLR-WEB10K_model/'\n",
    "    model_set = ['Listnet_model.txt']\n",
    "    #model_set = ['Ranknet_model.txt','LambdaMART_model.txt','Listnet_model.txt','LinearRegression_model.txt','coordinateascent_model.txt','Randomforests_model.txt']\n",
    "    for MODEL in model_set:\n",
    "        model = model_path + MODEL\n",
    "\n",
    "        for f in range(1,2):\n",
    "        # the path of data\n",
    "            datapath = 'MSLR-WEB10K/Fold{}/'.format(f)\n",
    "            train_path = datapath + 'train.txt'\n",
    "            test_path = datapath + 'test.txt'\n",
    "            modelname = model.split(\"_\")[1].split(\"/\")[-1]\n",
    "            dataname = datapath.split('/')[0] +'_'+ datapath.split('/')[1].split('Fold')[1]\n",
    "\n",
    "            # saving path and save files\n",
    "            NDCGdata_path = 'NDCGdata/'\n",
    "            temp_path = 'temp_data4/'\n",
    "\n",
    "\n",
    "            # get train data and test data\n",
    "            X_train, y_query_train, Query_train = get_microsoft_data(train_path)\n",
    "            X_train = np.array(X_train)\n",
    "            X_test, y_query_test, Query_test = get_microsoft_data(test_path)\n",
    "            X_test = np.array(X_test)\n",
    "            expected_value = np.mean(X_train, axis=0)\n",
    "\n",
    "            # separate the test set\n",
    "            test_data, test_y_query, test_Query, q_d_len = separate_set(y_query_test, X_test, Query_test)\n",
    "\n",
    "            resultfile_NDCG = 'resultfile/' + '{}_{}_MATRIX_NDCG.txt'.format(dataname,modelname)\n",
    "            resultfile_tau = 'resultfile/' + '{}_{}_MATRIX_tau.txt'.format(dataname,modelname)\n",
    "            resultfile_ratio =  'resultfile/' + '{}_{}_MATRIX_ratio.txt'.format(dataname,modelname)\n",
    "            for threshold_flag in range(4):\n",
    "                with Pool(10) as p:\n",
    "                    #print(p.map(loop_query, [query_index for query_index in range(10)]))\n",
    "                    print(p.map(loop_query, [query_index for query_index in range(len(test_data))]))\n",
    "                for feature_number in (5,10):\n",
    "                    NDCG_file_name = NDCGdata_path + '{}_MATRIX_{}features_threshold{}'.format(dataname,feature_number,threshold_flag) + modelname + '.txt'\n",
    "                    NDCG_file_matrix = NDCGdata_path + '{}_MATRIX_matrix_{}features_threshold{}'.format(dataname,feature_number,threshold_flag)  + modelname + '.txt'\n",
    "                    ranklist_file = NDCGdata_path + '{}_ranklist_MATRIX_{}features_threshold{}'.format(dataname,feature_number,threshold_flag)  + modelname + '.txt'\n",
    "                    rerank_ndcg(NDCG_file_name)\n",
    "                    NDCG =  write_average(NDCG_file_name)\n",
    "                    rerank_ndcg(ranklist_file)\n",
    "                    rerank_ndcg(NDCG_file_matrix)\n",
    "                    ratio = write_ratio(NDCG_file_name)\n",
    "                    tau = write_tau(NDCG_file_name)\n",
    "                    with open(resultfile_NDCG, 'a') as NDCG_result:\n",
    "                        NDCG_result_line  = str(NDCG) + \"\\n\"\n",
    "                        NDCG_result.write(NDCG_result_line)\n",
    "                    with open(resultfile_tau,'a') as tau_result:\n",
    "                        tau_result_line  = str(tau) + \"\\n\" \n",
    "                        tau_result.write(tau_result_line)\n",
    "                    with open(resultfile_ratio,'a') as ratio_result:\n",
    "                        ratio_result_line  = str(ratio) + \"\\n\" \n",
    "                        ratio_result.write(ratio_result_line)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
